{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "BA820 - Test 2 Recap",
      "provenance": [],
      "collapsed_sections": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "m5waXCngxL1M"
      },
      "source": [
        "# Test 2 Wrapup\n",
        "\n",
        "## Key Themes\n",
        "\n",
        "- Text processing (tokenization, considerations such as tokens, vocab size, thresholds)\n",
        "- document term matrix \n",
        "- All machine learning still applies once we have a DTM or a similar representation!\n",
        "  - dimensionality reduction\n",
        "  - clustering/uml tasks\n",
        "  - supervised tasks\n",
        "- Sentiment Analysis\n",
        "  - dictionary/lookup approaches\n",
        "  - some attempt to augment with rules-based modifiers\n",
        "  - Data annotation and hand-labeling is generally best for domain-specific needs\n",
        "- NER\n",
        "  - extract named entities from a corpus\n",
        "  - spacy has a generalized model, but its a model, so not always accurate for our specific domain needs\n",
        "  - when tuned for a specific problem, can help extract knowledge quickly versus humans in the loop\n",
        "- embeddings\n",
        "  - Instead of a sparse count representation, we can start to attempt to contextual meaning into static dense word/token vectors\n",
        "  - As with PCA directionally, we look to create this new feature space to represent our row/observation/document \n",
        "  - These representations can be used downstream in DR/UML/SML\n",
        "- beyond embeddings\n",
        "  - deep learning neural net architectures expanded Word2Vec and ushered in language modeling (multiple ML tasks learned/trained at once)\n",
        "  - Pretrained on large corpora, and like above, are general but might help improve our outcomes\n",
        "- Putting it all Together\n",
        "  - conversational AI combines intent classification and NER\n",
        "  - we can finetune deep learning models to leverage the generalized fits and learn tune the data to help fit our task\n",
        "  - Newer techniques for topic modeling draw upon learning embeddings, reducing those embeddings and calcuating similarity/distance to identify the semantic relationships in clusters\n",
        "\n",
        "## Additional Considerations for after BA820 \n",
        "\n",
        "- Data annotation in a notebook - https://github.com/dennisbakhuis/pigeonXT\n",
        "- Bulk labeling - https://github.com/RasaHQ/rasalit/blob/main/notebooks/bulk-labelling/bulk-labelling.ipynb\n",
        "- "
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Asefm13xxjIo"
      },
      "source": [
        "# installs\n",
        "! pip install -U spacy"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Q6M4cId2ziGY"
      },
      "source": [
        "# imports\n",
        "import pandas as pd\n",
        "import seaborn as sns\n",
        "\n",
        "from sklearn import metrics\n",
        "from sklearn.tree import DecisionTreeClassifier\n",
        "from sklearn.feature_extraction.text import CountVectorizer, TfidfVectorizer\n",
        "from sklearn.model_selection import train_test_split\n",
        "\n",
        "import spacy\n",
        "from spacy import cli \n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "pCdPoYpzz0B6",
        "outputId": "993df487-7949-40bb-e6e7-db1a6a3cd419"
      },
      "source": [
        "# spacy setup\n",
        "model = \"en_core_web_md\"\n",
        "cli.download(model)\n",
        "\n",
        "nlp = spacy.load(model)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\u001b[38;5;2mâœ” Download and installation successful\u001b[0m\n",
            "You can now load the package via spacy.load('en_core_web_md')\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "S4hQqgyQ0exj"
      },
      "source": [
        "# a dataset\n",
        "SQL = \"SELECT tweet_id, text, airline_sentiment from `questrom.datasets.airlines-tweets`\"\n",
        "df = pd.read_gbq(SQL, \"questrom\")"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "0I_3v_GW18BF",
        "outputId": "9f82e2fa-c6b1-44ef-8ae7-8975a7b0955f"
      },
      "source": [
        "# quick review\n",
        "df.info()"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "<class 'pandas.core.frame.DataFrame'>\n",
            "RangeIndex: 14640 entries, 0 to 14639\n",
            "Data columns (total 3 columns):\n",
            " #   Column             Non-Null Count  Dtype \n",
            "---  ------             --------------  ----- \n",
            " 0   tweet_id           14640 non-null  int64 \n",
            " 1   text               14640 non-null  object\n",
            " 2   airline_sentiment  14640 non-null  object\n",
            "dtypes: int64(1), object(2)\n",
            "memory usage: 343.2+ KB\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 143
        },
        "id": "8eu6eIfw2Dm5",
        "outputId": "59d3eccd-9152-4ce5-c405-2798a8e93796"
      },
      "source": [
        "df.sample(3)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>tweet_id</th>\n",
              "      <th>text</th>\n",
              "      <th>airline_sentiment</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>12331</th>\n",
              "      <td>570044681670696960</td>\n",
              "      <td>@united thank you.</td>\n",
              "      <td>positive</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3590</th>\n",
              "      <td>570110504254857217</td>\n",
              "      <td>@USAirways : You Make the Reservation; We'll M...</td>\n",
              "      <td>negative</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>6968</th>\n",
              "      <td>569859036360908801</td>\n",
              "      <td>@AmericanAir @MallowFairy And how many times, ...</td>\n",
              "      <td>negative</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>"
            ],
            "text/plain": [
              "                 tweet_id  ... airline_sentiment\n",
              "12331  570044681670696960  ...          positive\n",
              "3590   570110504254857217  ...          negative\n",
              "6968   569859036360908801  ...          negative\n",
              "\n",
              "[3 rows x 3 columns]"
            ]
          },
          "metadata": {},
          "execution_count": 11
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "nNaM_1b62E9Y"
      },
      "source": [
        "# split up the docs\n",
        "X_train, X_test, y_train, y_test = train_test_split(df.text, df.airline_sentiment, test_size=.3, random_state=820, stratify=df.airline_sentiment)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "RSKpy-To2qrM"
      },
      "source": [
        "# fit the Bag of Words via sklearn\n",
        "cv = CountVectorizer(max_features=15000)\n",
        "cv.fit(X_train)\n",
        "\n",
        "# get the dtms\n",
        "dtm_train = cv.transform(X_train)\n",
        "dtm_test = cv.transform(X_test)\n",
        "\n",
        "# these are dense, so lets make sure they are arrays\n",
        "dtm_train = dtm_train.toarray()\n",
        "dtm_test = dtm_test.toarray()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "n-v5zO9F3X2G",
        "outputId": "1bb6cc79-02b1-4a60-e06b-bbff4d212689"
      },
      "source": [
        "# what are the nlp pipelines in spacy\n",
        "nlp.pipe_names"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "['tok2vec', 'tagger', 'parser', 'attribute_ruler', 'lemmatizer', 'ner']"
            ]
          },
          "metadata": {},
          "execution_count": 16
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "JaBgi8J42-n6"
      },
      "source": [
        "# get the document vector representation with spacy\n",
        "\n",
        "# we can use pipe and disable the pipeline bits we dont need\n",
        "DISABLE = ['tagger', 'parser', 'attribute_ruler', 'lemmatizer', 'ner']\n",
        "docs_train = list(nlp.pipe(X_train, disable=DISABLE))\n",
        "docs_test = list(nlp.pipe(X_test, disable=DISABLE))\n",
        "\n",
        "\n",
        "# doc = nlp(\"Brock likes python\")"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "CPdf48za3enc"
      },
      "source": [
        "# extract above into doc vector representations\n",
        "# use pre-trained spacy word vectors\n",
        "\n",
        "dvm_train = [doc.vector for doc in docs_train]\n",
        "dvm_test = [doc.vector for doc in docs_test]"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "iEwsrjVS3whC",
        "outputId": "eb077140-7509-481a-a975-cf3222e89365"
      },
      "source": [
        "# quick review, what is distro of sentiment\n",
        "df.airline_sentiment.value_counts(dropna=False)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "negative    9178\n",
              "neutral     3099\n",
              "positive    2363\n",
              "Name: airline_sentiment, dtype: int64"
            ]
          },
          "metadata": {},
          "execution_count": 20
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "1UEZahCL4BNx",
        "outputId": "af5cc31f-ee05-482d-cd52-ac950bcebb80"
      },
      "source": [
        "# fit a tree with the bow - 30 seconds\n",
        "tree_bow = DecisionTreeClassifier(min_samples_split=150, random_state=820)\n",
        "tree_bow.fit(dtm_train, y_train)\n",
        "\n",
        "tree_vec = DecisionTreeClassifier(min_samples_split=150, random_state=820)\n",
        "tree_vec.fit(dvm_train, y_train)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "DecisionTreeClassifier(min_samples_split=150, random_state=820)"
            ]
          },
          "metadata": {},
          "execution_count": 27
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "SYYCz5Rl4NXe"
      },
      "source": [
        "# apply to get the predictions\n",
        "preds_dtm = tree_bow.predict(dtm_test)\n",
        "preds_dvm = tree_vec.predict(dvm_test)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "V-iWA63c5cYL"
      },
      "source": [
        "cr_bow = metrics.classification_report(y_test, preds_dtm)\n",
        "cr_vec = metrics.classification_report(y_test, preds_dvm)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "9pq3xxMk5psZ",
        "outputId": "c97f6178-a553-46e5-ba87-c686c61641d1"
      },
      "source": [
        "# report for bow/dtm\n",
        "print(cr_bow)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "              precision    recall  f1-score   support\n",
            "\n",
            "    negative       0.78      0.84      0.80      2753\n",
            "     neutral       0.50      0.45      0.47       930\n",
            "    positive       0.65      0.54      0.59       709\n",
            "\n",
            "    accuracy                           0.71      4392\n",
            "   macro avg       0.64      0.61      0.62      4392\n",
            "weighted avg       0.70      0.71      0.70      4392\n",
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "ttQU6ebG5szX",
        "outputId": "c49095e2-cefa-4e5e-b11a-4677d3415da6"
      },
      "source": [
        "# report for vectors\n",
        "print(cr_vec)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "              precision    recall  f1-score   support\n",
            "\n",
            "    negative       0.76      0.81      0.79      2753\n",
            "     neutral       0.45      0.42      0.43       930\n",
            "    positive       0.58      0.48      0.52       709\n",
            "\n",
            "    accuracy                           0.68      4392\n",
            "   macro avg       0.60      0.57      0.58      4392\n",
            "weighted avg       0.67      0.68      0.67      4392\n",
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "DVufRLHM5w8b"
      },
      "source": [
        ""
      ],
      "execution_count": null,
      "outputs": []
    }
  ]
}