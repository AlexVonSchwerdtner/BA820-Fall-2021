{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "12A-embeddings",
      "provenance": [],
      "collapsed_sections": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "code",
      "metadata": {
        "id": "ayhaQ8AcPFHx"
      },
      "source": [
        "##############################################################################\n",
        "## Fundamentals for pratical Text Analytics - document/word embeddings\n",
        "##                                            more spacy, \n",
        "##                                            gensim to build our own ----> spacy\n",
        "##                                            why:  dense numeric representations to capture meaning\n",
        "##                                                  use downstream -> similarity, clustering, ML\n",
        "##\n",
        "##\n",
        "## Learning goals:\n",
        "##                 - continue spacy\n",
        "##                 - foundational understanding of word vectors via Word2Vec\n",
        "##                 - can roll our own vectors\n",
        "##                 - generalized, pre-trained word vectors for S|UML tasks (intent classification)\n",
        "##\n",
        "##\n",
        "## Great resources\n",
        "##                 - https://spacy.io/usage/spacy-101\n",
        "##                 - https://spacy.io/universe/category/courses\n",
        "##\n",
        "##\n",
        "##############################################################################"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "j_R7-hTzQyzQ"
      },
      "source": [
        "# installs\n",
        "! pip install -U spacy \n",
        "! pip install -U textacy\n",
        "! pip install newspaper3k\n",
        "! pip install afinn\n",
        "! pip install whatlies"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "0nCDfEpzQy3_"
      },
      "source": [
        "# imports\n",
        "import spacy\n",
        "from spacy import cli\n",
        "from spacy import displacy\n",
        "\n",
        "import pandas as pd\n",
        "import numpy as np\n",
        "from scipy.spatial.distance import pdist, cdist, squareform\n",
        "import seaborn as sns\n",
        "\n",
        "\n",
        "# upcoming!\n",
        "# from textacy.extract.keyterms import textrank\n",
        "import gensim\n",
        "\n",
        "import textacy\n",
        "\n",
        "from newspaper import Article\n",
        "import json\n",
        "\n",
        "from afinn import Afinn\n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "xpCbWS6RE6TN"
      },
      "source": [
        "# use spacy cli\n",
        "MODEL = \"en_core_web_md\"\n",
        "\n",
        "# https://spacy.io/models/en\n",
        "cli.download(MODEL)\n",
        "\n",
        "# nlp = language model\n",
        "nlp = spacy.load(MODEL)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "N60MZcqlQr4c"
      },
      "source": [
        "############################################ WARMUP\n",
        "##\n",
        "##\n",
        "## Scrape the Wikipedia Entry for the Netflix series Squid Game\n",
        "## https://en.wikipedia.org/wiki/Squid_Game\n",
        "##\n",
        "## use the pre-loaded spacy NER model to parse the entities\n",
        "## parse the entities into a dataframe\n",
        "## create a barplot summarizing count by entity type\n",
        "## TRICKY:  make it a horizontal barplot with the most frequent entity at the top of the chart\n",
        "## "
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "nO0P9S-TQrsM"
      },
      "source": [
        ""
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "LHuNJ545RmXm"
      },
      "source": [
        ""
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "prsU8Wv1Rmb9"
      },
      "source": [
        ""
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "nvFe2T-5Rme_"
      },
      "source": [
        ""
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "OaCQTKnZRmh2"
      },
      "source": [
        ""
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Ubie_jaqRmkL"
      },
      "source": [
        "############################################ Word/Doc Vectors\n",
        "##\n",
        "##"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "2SP4rmYARpvR"
      },
      "source": [
        "# lets review a simple document\n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "VadxUj8NSpv4"
      },
      "source": [
        "# spacy is a pipeline\n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "gNG6EJaGR3Yk"
      },
      "source": [
        "# remember, we can slice up docs into tokens/spans\n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ygD_K_vRSLYP"
      },
      "source": [
        "# tokens have all sorts of attributes that were learned\n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "8ip4s9EOwVsR"
      },
      "source": [
        "# worth noting, a document can be comprised of sentences\n",
        "# remember that we used to download punkt from nltk?\n",
        "# that was a sentence tokenizer (divide into sentences)\n",
        "# spacy has this built in\n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ah9YNbSbUfZ_"
      },
      "source": [
        ""
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ORlTu0bUSlSt"
      },
      "source": [
        "####################################### quick departure\n",
        "# above we checked against spacy's learned vocabulary\n",
        "# this is a check to see if a token is out-of-vocabulary (OOV)\n",
        "\n",
        "# model reviews:\n",
        "# https://spacy.io/usage/models\n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "QTCeTza4UTHV"
      },
      "source": [
        "# this is just for reference\n",
        "# \n",
        "\n",
        "# v = nlp.vocab.vectors\n",
        "# v.shape"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "skGk_-OZV7tk"
      },
      "source": [
        "# spacy stores text and tokens effeciently \n",
        "# https://spacy.io/usage/spacy-101#vocab\n",
        "\n",
        "# spacy provides a way to lookup the vectors\n",
        "# nlp.vocab.strings[\"golf\"]\n",
        "\n",
        "# and we can reverse\n",
        "# nlp.vocab.strings[18149141486079540445]\n",
        "\n",
        "## spacy is very flexible, and while vectors can be added and edited, \n",
        "## we can just include our own, which we will do later"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "BGO7Kbw0W3oT"
      },
      "source": [
        "#######################################  Vectors/Embeddings\n",
        "##\n",
        "## You have heard me use this term quite a bit\n",
        "## we have seen this via PCA ----> take a large feature space and re-represent this in a new space\n",
        "##     the goal was to encode information and reduce noise, right?\n",
        "##\n",
        "## we saw this in Tsne (2 embeddings) and UMAP (can be 2 or more depending on our needs)\n",
        "## \n",
        "## \n",
        "## Well in text, we have the same idea\n",
        "## we could always use the tools above, but there this is a \"hot\" field right now -> embeddings\n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "LVvzSQikp_3C"
      },
      "source": [
        "\n",
        "\n",
        "![](https://miro.medium.com/max/2224/0*K5a1Ws_nsbEjhbYk.png)\n",
        "\n",
        "> Above we can see words can be represented in these highly dimensional spaces.  The aim is to encapsulate context.  Remember bag-of-words removes sequence/order!\n",
        "\n",
        "\n",
        "![](https://jalammar.github.io/images/word2vec/king-analogy-viz.png)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "vR9YLRNw5xiu"
      },
      "source": [
        "![](https://miro.medium.com/max/1400/1*cuOmGT7NevP9oJFJfVpRKA.png)\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "HieVHB46p_7E"
      },
      "source": [
        "# get some vectors\n",
        "\n",
        "# king = nlp(\"king\").vector\n",
        "# man = nlp(\"man\").vector\n",
        "# woman = nlp(\"woman\").vector\n",
        "# queen = nlp(\"queen\").vector\n",
        "# jester = nlp(\"jester\").vector\n",
        "# court = nlp(\"court\").vector\n",
        "# golf = nlp(\"golf\").vector"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "K6Kk2FdBuz1D"
      },
      "source": [
        "# what do we have\n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "mUiSy-5nu3VJ"
      },
      "source": [
        "# a quick preview\n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Re4xOhrnp_9-"
      },
      "source": [
        "# some math\n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "bOUSqmHxqAAi"
      },
      "source": [
        "# the comparison set\n",
        "\n",
        "# lookups = np.stack([queen, jester, court, golf])\n",
        "# lookups.shape"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "-C1o3KZGqACp"
      },
      "source": [
        "# we can use cdist manually\n",
        "# comp_list = ['queen', 'jester', 'court', 'golf']\n",
        "\n",
        "# the test calc needs to be 2-d\n",
        "\n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "7xxGesdmqAFI"
      },
      "source": [
        "# the comps -- cdist expected test to be 2d, so we used expand dims above\n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "3UVEpcDWZiog"
      },
      "source": [
        "# lets plot the distances as a barplot\n",
        "\n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "65pnrz-6ymLT"
      },
      "source": [
        "# so what did we see\n",
        "# it was a small test, but conceptually we saw how these vectors can be compared\n",
        "# we used distance to compare the numeric vectors and manually find the most similar\n",
        "# contrived example, but sets up the concepts"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "h1bjlLl_0sRt"
      },
      "source": [
        "# there are some great toolkits that have been created\n",
        "# to breakdown and explore all sorts of embeddings\n",
        "\n",
        "# lots you can do here, but from some of the dev rel folks at rasa, which\n",
        "# we will briefly see next class!\n",
        "# https://github.com/RasaHQ/whatlies"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "V4o0F2cI03Ds"
      },
      "source": [
        "## let's go back to the tweet\n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "SeIpB2fs2oBi"
      },
      "source": [
        "# what do we get for a token that is OOV?\n",
        "\n",
        "# nlp('🔥').vector\n",
        "\n",
        "\n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "XZ3OYN-82wA0"
      },
      "source": [
        "## what do you notice?\n",
        "## this is a convention of spacy\n",
        "## for OOV tokens, spacy doesn't fail, it simply returns an array of zeroes"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "IfZlU5WZ29cZ"
      },
      "source": [
        "# lets review a doc vector\n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "YnQWy9j-3MhY"
      },
      "source": [
        "# how do we think the doc vector is constructed?\n",
        "# vecs = []\n",
        "# for token in doc:\n",
        "#   vecs.append(token.vector)\n",
        "\n",
        "# make it a numpy array\n",
        "# va = np.array(vecs)\n",
        "\n",
        "# vam = va.mean(axis=0)\n",
        "# vam.shape\n",
        "\n",
        "# compare\n",
        "# np.all(vam == dv)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ifpZAuKW3yD1"
      },
      "source": [
        "# remember spans?\n",
        "# same still applies - token vectors are averaged over the docs and spans to represent the document"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "fNfB1bGXF9X3"
      },
      "source": [
        ""
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "6rb-RP5G4aI7"
      },
      "source": [
        "#######################################  YOUR TURN\n",
        "## \n",
        "## scrape the text from the three articles from the URLs below\n",
        "## generate the doc vectors\n",
        "## what is the most similar article to URL1 via cosine distance?\n",
        "#\n",
        "# URL1 = \"https://www.boston.com/weather/weather/2021/11/26/boston-ma-snow-forecast-friday-nov-26-2021/\"\n",
        "# URL2 = \"https://www.sportingnews.com/us/fantasy/news/nfl-week-12-weather-updates-lack-of-rain-wind-snow-in-forecast-eases-fantasy-football-start-em-sit-em-decisions/lueadzpkttxa1l2nzyr70hr18\"\n",
        "# URL3 = \"https://www.marketwatch.com/story/the-u-s-stock-market-suffers-ugly-black-friday-selloff-here-are-the-biggest-losers-and-winners-11637952898\"\n",
        "## \n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "rm0CeBWf8eZy"
      },
      "source": [
        ""
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "fyjr0bgS8VdI"
      },
      "source": [
        "#######################################  UP NEXT\n",
        "## \n",
        "## Team data challenge!\n",
        "# "
      ],
      "execution_count": null,
      "outputs": []
    }
  ]
}